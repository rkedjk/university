# 1. Случайные события. Примеры

Случайное событие (**событие**) --- любой факт, который в результате
опыта (испытания) может произойти либо не произойти

**Опыт** (испытание) --- то, результат чего непредсказуем точно

**Исход опыта** --- результат опыта. Взаимоисключающие исходы образуют
элементарные события

События обозначаются заглавными латинскими буквами

**Достоверное событие** --- это событие, которое в опыте происходит
обязательно. Обозначается символом **Ω**

**Невозможное событие** --- это событие, которое в опыте никогда не
происходит. Обозначается символом ∅

**Пример.** Опыт - 1 раз брошен кубик -- Событие «выпало меньше 10
очков» - достоверное -- Событие «выпало больше 10 очков» - невозможное

**Полная группа событий** --- это совокупность событий, хотя бы одно из
которых в опыте обязательно происходит

Два события называют **несовместными**, если в опыте они не могут
произойти одновременно Два события называют **совместными**, если в
опыте они могут произойти одновременно

Несколько событий называют **попарно несовместными**, если в опыте
никакие два из них не могут произойти одновременно

Несколько событий называют **несовместными в совокупности**, если в
опыте все они не могут произойти одновременно

Если события попарно несовместные, то они обязательно несовместные в
совокупности

Если события несовместные в совокупности, то они **не** обязательно
попарно несовместные

Два события называют **равными**, если в опыте одно из них происходит
только тогда, когда происходит другое событие. В противном случае
события **неравные**

Равные события: **A=B**

Неравные события: **A≠B**

Принято считать, что невозможное событие равно невозможному событию: ∅=∅

Два события называют **равновозможными**, если есть основание считать,
что ни одно из этих событий не является объективно более возможным, чем
другое

**Несовместные** и **равновозможные** события, образующие **полную
группу**, называют **случаями** (шансами)

**Противоположное** событие для события A --- это событие, которое в
опыте происходит только тогда, когда не происходит событие A

Обозначение: $\overline{\mathbf{A}}$

**Противоположные** события являются **несовместными** и образуют
**полную группу**

Событие A **влечёт за собой** событие B, если в опыте событие В
обязательно происходит, когда происходит событие A

Обозначение: **A⊂B**

Исход называют благоприятным некоторому событию, если появление этого
исхода влечёт за собой появление данного события

**Примеры:**

● Опыт --- один раз брошен кубик

-- Событие A --- выпало 5 очков

-- Событие В --- выпало меньше 4 очков

-- Событие С --- выпало чётное число очков

-- Всего исходов опыта 6

● Опыт --- один подброшена монета

-- Событие А --- выпал «орёл»

-- Событие В --- выпала «решка»

-- Всего исходов опыта 2

● Опыт --- произведено n выстрелов по мишени

-- Событие А --- 5 попаданий в цель

-- Событие В --- попаданий в цель

-- Исходы опыта:

**m** попаданий, **n-m** промахов

Всего исходов:$2^{n}$ нужно подсчитать все возможные комбинации из
промахов и попаданий при заданном **n**

# 2. Операции над событиями. Примеры

**Сумма** событий --- это событие, которое происходит тогда, когда в
опыте происходит хотя бы одно из событий **A1, A2, \..., An**

Обозначение: **A1+A2+\...+An**

Для совместных событий **A** и **B** событие **A+B** означает или
наступление события **A**, или наступление события **B**, или обоих
событий вместе

Для несовместных событий **A** и **B** их сумма означает либо
наступление события **A**, либо наступление события **B**

**Пример**: Появление чётной грани игральной кости есть сумма трёх
событий: выпадение 2, выпадение 4, выпадение 6.

**Произведение** событий **A1, A2, \..., An** - это событие, которое
происходит тогда, когда в опыте одновременно происходят все события **A1
, A2 ,\..., An**

Обозначение: **A1⋅A2⋅\...⋅An**

**Пример:** пусть событие **А** -- при бросании двух монет появление
герба на первой монете, событие **В** -- появление герба на второй
монете; тогда произведение **А·В** -- это появление гербов на обеих
монетах.

**Разность** событий **A** и **B** --- это событие, которое происходит
тогда, когда в опыте событие **A** произойдёт, а событие **B** не
произойдёт

Обозначение: **A−B**

**Пример** -- **А** -- сдача экзаменационной сессии, **В** -- получение
стипендии, тогда **А-В** -- сдача сессии с недостаточно высоким для
получения стипендии результатом.

# 3. Классическое и статистическое определение вероятности

Согласно классическому определению, **вероятность** события A равна
отношению числа исходов, благоприятствующих событию A, к общему числу
исходов

Обозначение: **P(A)= k / n**

**P(A)** - вероятность события **A**

**k** - число исходов, благоприятствующих событию **A**

**n** - общее число исходов опыта

**Свойства вероятности:**

Вероятность любого события заключена между 0 и 1: **0⩽P(A)⩽1**

Вероятность достоверного события равна 1: **P(Ω)=1**

Вероятность невозможного события равна 0: **P(∅)=0**

Классическая формула не всегда позволяет рассчитать вероятность события.
Поэтому для оценки вероятности события применяют другой подход

**Статистическая вероятность** события **A** --- это относительная
частота появления этого события в n проведённых испытаниях:
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image1.png)


**m** --- число испытаний, в которых появилось событие **A**

**n** --- общее число испытаний

# 4. Сходимость по вероятности. Принцип практической уверенности

**Сходимость по вероятности**

Величина $X_{n}$ **сходится по вероятности** к величине **a**, если при
сколь угодно малом **ε** вероятность неравенства
$\left| X_{n} - a \right| < \varepsilon$

с увеличением **n** неограниченно приближается к единице

При увеличении числа опытов частота события не стремится к вероятности
события, а сходится к ней по вероятности:
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image2.png)


**Принцип практической уверенности**

События, вероятности которых очень малы (близки к нулю) или очень велики
(близки к единице), называются соответственно практически невозможными
или практически достоверными событиями

# 5. Основные правила и формулы комбинаторики

Пусть $А_{i}(i = 1,2,\ldots,n)\ $- элементы конечного множества

**Правило суммы**. Если элемент $\mathbf{A}_{\mathbf{1}}$ можно выбрать
$\mathbf{n}_{\mathbf{1}}$ способами, элемент
$\mathbf{A}_{\mathbf{2}}\mathbf{-}\mathbf{n}_{\mathbf{2}}$ - способами,
элемент $\mathbf{A}_{\mathbf{k}}\mathbf{-}\mathbf{n}_{\mathbf{k}}$ -
способами, то выбор одного из элементов: или $\mathbf{A}_{\mathbf{1}}$,
или $\mathbf{A}_{\mathbf{2}}$,..., или $\mathbf{A}_{\mathbf{k}}$ может
быть осуществлён способами
$\mathbf{n}_{\mathbf{1}}\mathbf{+}\mathbf{n}_{\mathbf{2}}\mathbf{+ \ldots +}\mathbf{n}_{\mathbf{k}}$

**Правило произведения**. Если элемент
$\mathbf{A}_{\mathbf{1}}\mathbf{\ }$можно выбрать
$\mathbf{n}_{\mathbf{1}}$ способами, после этого элемент
$\mathbf{A}_{\mathbf{2}}$ может быть выбран $\mathbf{n}_{\mathbf{2}}$
способами и т.д., после каждого $\mathbf{(}\mathbf{k}\mathbf{- 1)}$
выбора элемент может быть выбран $\mathbf{n}_{\mathbf{k}}$ способами, то
выбор всех элементов $A_{1},A_{2},\ldots,\ A_{k}$ в указанном порядке
может быть осуществлён
$\mathbf{n}_{\mathbf{1}}\mathbf{*}\mathbf{n}_{\mathbf{2}}\mathbf{*\ldots*}\mathbf{n}_{\mathbf{k}}$
способами

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image3.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image4.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image5.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image6.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image7.png)


# 6. Теорема сложения вероятностей. Следствия

Вероятность суммы **двух несовместных** событий равна сумме вероятностей
этих событий:

**P (A + B) = P(A) + P(B)**

Вероятность суммы событий **трех попарно несовместных** событий равна
сумме вероятностей этих событий:

**P (A + B + C) = P(A) + P(B) + P(C)**

Общий случай теоремы для n событий:

**P
(**$\sum_{\mathbf{i\  = \ 1}}^{\mathbf{n}}\mathbf{A}_{\mathbf{i}}$**)=**$\mathbf{\ }\sum_{\mathbf{i\  = \ 1}}^{\mathbf{n}}{\mathbf{P(}\mathbf{A}_{\mathbf{i}}\mathbf{)}}$

Вероятность суммы **двух совместных** событий выражается формулой:

**P(A + B) = P(A) + P(B) -- P(A \* B)**

Вероятность суммы **трех совместных** событий вычисляется по формуле:

**P(A + B + C) = P(A) + P(B) + P(C) -- P(A\*B) - P(A\*C) -- P (B\*C) --
P(A \* B \* C)**

**Следствие 1**: если события A1, A2, A3...An образуют полную группу
попарно несовместных событий, то сумма их вероятностей равна единице:

$\sum_{\mathbf{i}\mathbf{\  = \ 1}}^{\mathbf{n}}{\mathbf{P}\mathbf{(}\mathbf{A}_{\mathbf{i}}\mathbf{)}}$
**= 1**

**Следствие 2**: Сумма вероятностей противоположных событий равна
единице:

**P(A) + P(**$\overline{\mathbf{A}}$**) = 1**

# 7. Теорема умножения вероятностей. Следствия

Вероятность произведения двух событий равна произведению вероятности
одного из них на условную вероятность другого, вычисленную при условии,
что первое имело место.

P(A \* B) = P(A) \* P(B \| A)

P(A \* B) = P(B) \* P(A \| B)

**P(A \| B) =**
$\frac{\mathbf{P}\mathbf{(}\mathbf{A}\mathbf{\ *\ }\mathbf{B}\mathbf{)}}{\mathbf{P}\mathbf{(}\mathbf{B}\mathbf{)}}$

Вероятность произведения трех событий определяется формулой:

**P(A \* B \* C) = P(A) \* P(B \| A) \* P(C \| A \* B)**

Если события A, B, C -- независимые, то

**P(A \* B) = P(A) \* P(B)**

**P(A \* B \* C) = P(A) \* P(B) \* P(C)**

**Следствия теоремы умножения вероятностей.**

**Следствие 1**: если событие А не зависит от события В, то и событие В
не зависит от события А, т. е если

**P(A) = P (A \| B),** То и **P(B) = P (B \| A)**

**Следствие 2**: Вероятность произведения двух независимых событий равно
произведению вероятностей этих событий:

**P (A \* B) = P(A) \* P(B)**

# 8. Условная вероятность. Зависимые и независимые события

**Условная вероятность.**

Вероятность события **А**, которая зависит от того, произошло ли или нет
событие В, называют **условной вероятностью** события **А.**

Обозначение: **P(A \| B)**

**P(A \| B) = P(A)** -- события **А** и **В** независимые.

**P(A \| B)** $\mathbf{\neq}$ **P(A)** -- события **А** и **В**
зависимые.

**Зависимые и независимые события.**

Событие А называется **независимым** от события В, если вероятность
события А не зависит от того, наступило или нет событие В.

Событие А называется **зависимым** от события В, если вероятность
события А меняется в зависимости от того, наступило или нет событие В.

Опыт -- бросание двух монет:

Событие А -- появление герба на первой монете.

Событие В -- появление герба на второй монете.

Вероятность события А не зависит от наступления события В.

# 9. Формула полной вероятности

Формула полной вероятности является следствием теорем сложения и
умножения вероятностей.

Пусть событие **А** может произойти вместе с одним из образующих полную
группу несовместных событий **H1, H2, ..., Hn** (их называют гипотезами)

Вероятность события **А** вычисляется по формуле:

**P(A) =**
$\sum_{\mathbf{i\  = \ 1}}^{\mathbf{n}}{\mathbf{P(}\mathbf{H}_{\mathbf{i}}\mathbf{)*}\mathbf{P}\mathbf{(}\mathbf{A}\mathbf{\ |\ }\mathbf{H}_{\mathbf{i}}\mathbf{)}}$

# Формула Байеса

Дана полная группа несовместных событий **H1, H2, ..., Hn** и их
вероятности до проведения опыта:

**P(H1), P(H2),...,P(Hn)**

Проведен опыт, в результате которого состоялось событие **А**. Найти
**P(Hi \| A)** можно по формуле Байеса:

$$\mathbf{P(}\mathbf{H}_{\mathbf{i}}\mathbf{\ |\ A) =}\frac{\mathbf{P(}\mathbf{H}_{\mathbf{i}}\mathbf{)*P(}\mathbf{A\ |\ H}_{\mathbf{i}}\mathbf{)}}{\sum_{\mathbf{i\  = \ 1}}^{\mathbf{n}}{\mathbf{P(}\mathbf{H}_{\mathbf{i}}\mathbf{)*P(}{\mathbf{A\ |\ }\mathbf{H}}_{\mathbf{i}}\mathbf{)}}}$$

Теорема гипотез позволяет пересчитать вероятности гипотез при
наступлении события (после проведения опыта).

Наступление события позволяет получить новую информацию, которая
позволяет корректировать выдвинутые гипотезы (вероятности гипотез).

# Частная теорема о повторении опытов

Если вероятность события $\mathbf{А}$ не изменяется от опыта к опыту, то
имеет место **частная теорема о повторении опытов**.

Если производится $\mathbf{n}$ независимых опытов, в каждом из которых
событие $\mathbf{А}$ появляется с вероятностью p, то вероятность Pm, n
того, что событие $\mathbf{А}$ появится ровно $\mathbf{m}$ раз,
выражается формулой:

$$\mathbf{P}_{\mathbf{m}\mathbf{,}\mathbf{n}}\mathbf{=}\mathbf{C}_{\mathbf{n}}^{\mathbf{m}}\mathbf{*}\mathbf{p}^{\mathbf{m}}\mathbf{*}\mathbf{q}^{\mathbf{n}\mathbf{-}\mathbf{m}}\mathbf{,\ где\ }\mathbf{q}\mathbf{\  = \ 1 - \ }\mathbf{p}$$

Формулу выше называют $\mathbf{схемой\ Бернулли}$.

Вероятности $\mathbf{P}_{\mathbf{m}\mathbf{,}\mathbf{n}}\ $являются
членами разложение бинома
${\mathbf{(}\mathbf{p}\mathbf{\  + \ }\mathbf{q}\mathbf{)}}^{\mathbf{n}}$

Если в каждом опыте из серии может произойти одно из событий **A1, A2,
... Ak**, с соответствующей вероятностью **p1,p2,...,pk**, то
вероятность появления **m1** раз события **A1, m2** раз события **A2,
mk** раз события **Akm** определятся полиномиальной схемой:

$$\mathbf{P(}\mathbf{m}_{\mathbf{1}}\mathbf{,}\mathbf{m}_{\mathbf{2}}\mathbf{,...,}\mathbf{m}_{\mathbf{k}}\mathbf{) =}\frac{\mathbf{n!}}{\mathbf{m}_{\mathbf{1}}\mathbf{!\ *\ }\mathbf{m}_{\mathbf{2}}\mathbf{\ !...,*}\mathbf{m}_{\mathbf{k}}\mathbf{!}}\mathbf{p}_{\mathbf{1}}^{\mathbf{m}_{\mathbf{1}}}\mathbf{*}\mathbf{p}_{\mathbf{2}}^{\mathbf{m}_{\mathbf{2}}}\mathbf{*...*}\mathbf{p}_{\mathbf{k}}^{\mathbf{m}_{\mathbf{k}}}$$

**n =**
$\mathbf{m}_{\mathbf{1}}\mathbf{\  + \ }\mathbf{m}_{\mathbf{2}}\mathbf{\  + \ ...\  +}\mathbf{m}_{\mathbf{k}}\mathbf{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }\mathbf{p}_{\mathbf{1}}\mathbf{+}\mathbf{p}_{\mathbf{2}}\mathbf{+ ... +}\mathbf{p}_{\mathbf{k}}\mathbf{= 1}$

# Общая теорема о повторении опытов

Если вероятность события $\mathbf{А}$ каждый раз различна при серии
испытаний, то имеет место **общая теорема о повторении опытов**.

Если в каждом опыте вероятность появления события $\mathbf{А}$ различна,
то применяется общая теорема о повторении опытов.

Пусть проводятся n независимых опытов, в каждом из которых может
появиться или не появиться событие $\mathbf{А}$. Вероятность появления
события $\mathbf{А\ }$в опыте $\mathbf{i}$ равна $\mathbf{pi}$,
вероятность непоявления события $\mathbf{А}$
$\mathbf{равна\ }\mathbf{q}_{\mathbf{i}}\mathbf{\  = \ 1\ –\ }\mathbf{p}_{\mathbf{i}}$.

Общая теорема о повторении опытов выражается формулой:

$$\prod_{\mathbf{i}\mathbf{\  = \ 1}}^{\mathbf{n}}\left( \mathbf{q}_{\mathbf{i}}\mathbf{+}\mathbf{p}_{\mathbf{i}}\mathbf{*}\mathbf{z} \right)\mathbf{\  = \ }\sum_{\mathbf{m}\mathbf{\ \  = 0}}^{\mathbf{n}}{\mathbf{P}_{\mathbf{m}\mathbf{,}\mathbf{n}}\mathbf{*}}\mathbf{z}^{\mathbf{m}}$$

Вероятность того, что событие А в n независимых опытах появится ровно m
раз, равна коэффициенту при
$\mathbf{z}^{\mathbf{m}}\mathbf{\ }$($\mathbf{z}$ -- произвольный
параметр).

Выражение
$\mathbf{fi}\mathbf{(}\mathbf{z}\mathbf{)\  = \ }\prod_{\mathbf{i}\mathbf{\  = \ 1}}^{\mathbf{n}}\left( \mathbf{q}_{\mathbf{i}}\mathbf{+}\mathbf{p}_{\mathbf{i}}\mathbf{*}\mathbf{z} \right)$
называют производящей функцией вероятностей
$\mathbf{R}_{\mathbf{m}\mathbf{,\ }\mathbf{n}}\mathbf{.}$

Общая теорема обращается в частную
при$\mathbf{\ }\mathbf{p}_{\mathbf{1}}\mathbf{\  = \ }\mathbf{p}_{\mathbf{2}}\mathbf{= \ \ldots\  = \ }\mathbf{p}_{\mathbf{n}}\mathbf{.}$

Пусть событие $\mathbf{C}_{\mathbf{m}}$ состоит в том, что событие **А**
появилось не менее **m** раз. Тогда вероятность этого события
$\mathbf{R}_{\mathbf{m}\mathbf{,}\mathbf{n}}$**.**

# Формула Пуассона

Теорема Пуассона:

Если вероятность $\mathbf{p}$ наступления события. $\mathbf{А}$ в каждом
испытании стремится к нулю при неограниченном увеличении $\mathbf{n}$,
то вероятность $\mathbf{P}_{\mathbf{m}\mathbf{,}\mathbf{n}}$
определяется соотношением:

$$\mathbf{P}_{\mathbf{m}\mathbf{,}\mathbf{n}}\mathbf{\approx}\frac{\mathbf{\lambda}^{\mathbf{m}}\mathbf{*}\mathbf{e}^{\mathbf{- \lambda}}}{\mathbf{m!}}\mathbf{=}\mathbf{P}_{\mathbf{m}}\mathbf{(\lambda)\ }$$

# Формулы Муавра-Лапласа

**Локальная теорема Муавра -- Лапласа:**

Если вероятность р наступления события. **А** в каждом испытании
постоянна, отлична от нуля и единицы, то вероятность
$\mathbf{P}_{\mathbf{m}\mathbf{,}\mathbf{n}}$ определяется формулой:

$$\mathbf{P}_{\mathbf{m,n}}\mathbf{\approx}\frac{\mathbf{\varphi(x)}}{\sqrt{\mathbf{n\ *\ p\ *\ q}}}$$

Функцию $\mathbf{\varphi}$ **(x)** называют функцией Гаусса.

**Интегральная теорема Муавра -- Лапласа**

Если вероятность р наступления события. **А** в каждом испытании
постоянна, отлична от нуля и единицы, то при большом n вероятность того,
что **a \<= m \<= b** определяется формулой:

$$\mathbf{P(a\  < = \ m\  < = \ b)\  \approx \ }\mathbf{Ф(}\mathbf{x}_{\mathbf{2}}\mathbf{)\  - \ Ф\ (}\mathbf{x}_{\mathbf{1}}\mathbf{)}$$

**Где**
$\mathbf{x}_{\mathbf{1}}\mathbf{=}\frac{\mathbf{a\  - \ n\ *\ p}}{\sqrt{\mathbf{n\ *\ p\ *\ q}}}\mathbf{,\ }\mathbf{x}_{\mathbf{2}}\mathbf{=}\frac{\mathbf{b\  - \ n\ *\ p}}{\sqrt{\mathbf{n\ *\ p\ *\ q}}}$**,
n\*p\*q \>= 20**

$$\mathbf{Ф(х) =}\frac{\mathbf{1}}{\mathbf{2*\ }\mathbf{\pi}}\mathbf{*}\int_{\mathbf{0}}^{\mathbf{x}}\mathbf{e}^{\mathbf{-}\frac{\mathbf{t\hat{}2}}{\mathbf{2}}}\mathbf{*dt}$$

# Случайная величина. Способы её задания

**Случайная величина** -- величина, которая в результате опыта может
принять то или иное заранее неизвестное значение.

Способы задания: ряд распределения (только для ДВС - Дискретные
случайные величины), могильник распределения (только для ДВС), функция
распределения, плотность распределения (подходит для НСВ)

# Функция распределения случайной величины. Свойства

**Функция распределения** -- универсальный способ задания случайной
величины.

Функция распределения случайной величины Х -- это функция F(x) одной
переменной х, принимающей любые действительные значения.

Будем рассматривать события не Х = х, а Х \< x

Функция распределения -- это вероятность того, что случайная величина Х
примет значение, меньшее аргумента функции х.

F(x) = P(X \< x)

Функция распределения задает как дискретные, так и непрерывные случайные
величины.

Свойства функции распределения:

Функция распределения F(x) есть неубывающая функция, т.е

$$x_{2}\  > \ x_{1}\ F(x_{2})\ \  > = \ {F(x}_{1})\ $$

На минус бесконечности функция распределения принимает значение 0

F($- \infty$) = 0

На плюс бесконечности функция распределения принимает значение 1.

F($+ \infty$) = 1

# Вероятность попадания НСВ на заданный участок

**Непрерывные случайные величины (НСВ)** -- принимают любое значение из
заданного промежутка (таких значений бесконечно много):

1)  Координата точки попадания при выстреле.

2)  Ошибка при измерениях расстояния.

3)  Время безотказной работы прибора.

**Вероятность попадания НСВ на заданный участок.**

Рассмотрим полуинтервал \[$\alpha,\ \beta)$

Попадание случайной величины на данный полуинтервал равносильно
неравенству:

$$\alpha < = \ X < \ \beta$$

Рассмотрим события A, B, C такие, что:

A : X \<$\ \beta$

B: X \< $\alpha$

C: $\alpha < = \ X < \ \beta$

По теореме сложения вероятностей:

P(A) = P(B +C)= P(B) + P(C)

P(X \< $\beta$) = P($X\  < \ \alpha$) + P($\alpha\  < = \ X\  < \beta$)

Используя функцию распределения можно записать:

F($\beta$) = F($\alpha$) + P($\alpha,\  < = \ X\  < \beta$)

Используя ...

Вероятность попадания случайной величины на заданный участок равна
приращению функции распределения на этом участке.

Рассмотрим предел:

$P(X = \ \alpha) = \lim_{\ \beta\  - > \ \alpha}{P(\alpha < = X < \ \beta)}$
=
$\lim_{\ \beta\  - > \ \alpha}{P(F\lbrack\beta\rbrack\  - \ F\lbrack\alpha\rbrack)}$

Если F(x) имеет разрыв в точке x=a, то предел **равен** **значению
скачка** функции в точке

Если F(x) непрерывна в точке , то предел **равен нулю**

# Плотность распределения. Свойства

Пусть F(x) -- непрерывна и дифференцируема.

Вычислим вероятность:

P(x \< X\< x + $\mathrm{\Delta}x$) = F(x + $\mathrm{\Delta}x$) -- F(x)

Разделим на $\mathrm{\Delta}x$, устремим $\mathrm{\Delta}x$ к нулю и
найдем предел:

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image8.png)


Кривая, изображающая плотность распределения, называется кривой
распределения.

Плотность распределения существует только для НСВ.

![C:\\Users\\lesha\\AppData\\Local\\Microsoft\\Windows\\INetCache\\Content.MSO\\3CDFD7A.tmp](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image9.png)


![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image10.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image11.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image12.png)


# Числовые характеристики случайных величин: характеристики положения

Для описания случайной величины иногда бывает достаточным указать
числовые характеристики, которые в сжатой форме отражают наиболее
существенные её особенности распределения.

**Характеристики положения:**

Математическое ожидание M\[X\] случайной величины -- это её среднее
значение.

Для ДСВ, имеющей ряд распределения:

  --------------------------------------------------------------------------
  $$x_{i}$$      $$x_{1}$$      $$x_{2}$$      ...            $$x_{n}$$
  -------------- -------------- -------------- -------------- --------------
  $$p_{i}$$      $$p_{1}$$      $$p_{2}$$      ...            $$p_{n}$$

  --------------------------------------------------------------------------

Математическое ожидание вычисляется по формуле.

M\[X\] = $\sum_{i\  = \ 1}^{n}{x_{i}*p_{i}}$

Для НСВ математическое ожидание вычисляется по формуле:\
M\[X\] = $\int_{- \infty}^{+ \infty}{x*f(x)dx}$

f(x) -- плотность распределения НСВ.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image13.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image14.png)


# Числовые характеристики случайных величин: квантили, квартили, вероятное отклонение

**Квантилью** порядка **p** случайной величины Х называют такое число
$x_{p}$, для которого выполняется следующее равенство.

Кванитли порядков 0,25; 0,5; 0,75 называют **квартилями** и обозначают
соответственно
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image15.png)


**Вероятным отклонением** называют величину **E =
0.5(**$\mathbf{k}_{\mathbf{3}}\mathbf{-}\mathbf{k}_{\mathbf{1}}$**)**

Для симметричных распределений вероятное отклонение определяется из
уравнение:

P(\|X -- M\[X\]\|$\leq E$)=0,5

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image16.png)


# Числовые характеристики случайных величин: моменты, дисперсия, среднее квадратическое отклонение

**Начальным моментом** порядка **S** называют величину:

1)  Для ДСВ -
    $a\lbrack X\rbrack = \sum_{i\  = \ 1}^{n}{x_{i}^{5}*p_{i}}$

2)  Для НСВ -
    $a\lbrack X\rbrack = \int_{- \infty}^{+ \infty}{x_{i}^{5}*f(x)dx}$

**Центральным моментом** порядка **S** называют величину:

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image17.png)


**Дисперсия** -- это **второй центральный момент**

\- для НСВ D\[X\] =
$\mu_{2}\lbrack X\rbrack\  = \ \sum_{i\  = \ 1}^{n}{(x_{i} - M\lbrack X\rbrack)*p_{i}}$

\- для ДСВ D\[X\] =
$\mu_{2}\lbrack X\rbrack\  = \ \int_{- \infty}^{+ \infty}{{(x\  - \ M\lbrack X\rbrack)}^{2}*f(x)dx}$

**Среднее квадратичное отклонение**

$$\sigma\lbrack X\rbrack = \sqrt{D\lbrack X\rbrack}$$

# Числовые характеристики случайных величин: асимметрия, эксцесс, коэффициент вариации

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image18.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image19.png)


# Центрированная случайная величина

Случайную величину $\overset{\circ}{X}$ кружок называют центрированной.

$\overset{\circ}{X}$= Х -- М\[X\] М\[$\overset{\circ}{X}$\] =
0$	\mu_{s}\lbrack X\rbrack\  = \ M\ \lbrack{\overset{\circ}{X}}^{S}\rbrack$
D\[X\] = M\[${\overset{\circ}{X}}^{2}$\]

# Распределение Бернулли. Пример

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image20.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image21.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image22.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image23.png)


# Биномиальное распределение. Пример (в презентациях он не рассматривает отдельно распределение Бернули и биноминальное, но также пропущено геометрическое распределение. Может тут в вопросах опечатка? \*)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image24.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image25.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image26.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image27.png)


# Распределение Пуассона. Пример

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image28.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image29.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image30.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image31.png)


# Равномерный закон распределения.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image32.png)


# Пример Экспоненциальный закон распределения.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image33.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image34.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image35.png)


# Пример Нормальный закон распределения.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image36.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image37.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image38.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image39.png)


# Пример Стандартный нормальный закон распределения. Правило трёх сигм

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image40.png)




![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image41.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image42.png)
![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image43.png)


# Система двух случайных величин. Функция распределения

**Определение**: Кортеж \<X, Y\> случайных величин X и Y,
рассматриваемых совместно, называется системой двух случайных величин.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image44.png)
 **Функция распределения системы двух случайных
величин.**

**Определение**:

Функция распределения системы \<X, Y\> случайных величин (дискретных или
непрерывных) -- это функция, значение F(x, y) которой для любых
действительных x и y равно вероятности того, что одновременно истинны
неравенства X \< x и Y \< y,

Т.е F(x, y) = P(X \< x, Y \< y). (Запятую можно условно заменить союзом
и).

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image45.png)


Всегда F(x, y) -- это неубывающая функция x и y (т.к F(x, y) -- это
вероятность).

0 \<= F(x, y) \<= 1

При любых действительных x и y.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image46.png)


![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image47.png)


# Числовые характеристики системы двух случайных величин

Числовые характеристики системы двух случайных величин

$$\alpha_{ks}\lbrack X,\ Y\rbrack\ \beta_{ks}\lbrack X,\ Y\rbrack$$

Основные изучаемые понятия

1)  Начальный момент системы двух случайных величин

2)  Центральный момент системы двух случайных величин

3)  Ковариация системы двух случайных величин

4)  Коэффициент корреляции системы двух случайных величин

5)  Коррелированные случайные величины

6)  Некоррелированные случайные величины

Числовые характеристики системы двух случайных величин

Пусть:

Х -- дискретная случайная величина с реализациями $x_{1},x_{2}...x_{m};$

Y -- дискретная случайная величина с реализациями $y_{1},y_{2}...y_{m};$

Пусть система \<X, Y\> имеет распределение вероятностей:

{\<$x_{1},y_{1},p_{11}$\>,
\<$x_{1},y_{2},p_{12} > ,..., < x_{m},y_{n},p_{mn} >$},

Где
$p_{ij}\  = \ P(X = \ x_{i},\ Y\  = \ y_{i});\ i\  = \ 1,\ 2,\ 3...m$; j
= 1, 2, 3...n.

# Дискретный вариационный ряд и его графическое изображение

**Случайная величина** -- Признак, **Реализация случайной величины** --
Вариант

Абсолютная частота варианта -- сколько раз встречается конкретный
вариант.

Частоты вариантов (относительная частота) -- абсолютная частота варианта
/ общее число вариантов.

Дискретный вариационный ряд для абсолютных частот:

  -----------------------------------------------------------------------
  Вариант                              Абсолютная частота варианта
  ------------------------------------ ----------------------------------
  2                                    2

  3                                    4

  4                                    3

  5                                    1
  -----------------------------------------------------------------------

Дискретный вариационный ряд для относительных частот:

  -----------------------------------------------------------------------
  Вариант                             Отн. частота
  ----------------------------------- -----------------------------------
  2                                   0,2

  3                                   0,4

  4                                   0,3

  5                                   0,1
  -----------------------------------------------------------------------

**Полигон** -- это многоугольник, график, на котором отображаются по
вертикали -- абсолютная частота варианта, по горизонтали -- вариант.

Это график для абсолютных частот:

Накопленная абсолютная частота для значения Х.

  -----------------------------------------------------------------------
  Значение х                Накопленная абсолютная частота для значения х
  ------------------------- ---------------------------------------------
  1                         0

  2                         0

  2,1                       2

  3                         2

  3,7                       6

  4                         6

  4,2                       9

  5                         9

  5,5                       10

  6                         10
  -----------------------------------------------------------------------

В правом столбце содержится кол-во абсолютных частот вариантов, меньших
варианту х.

То же самое можно сделать и для частот:

  -----------------------------------------------------------------------
  Значение х          Накопленная частота для значения х
  ------------------- ---------------------------------------------------
  1                   0

  2                   0

  2,1                 0,2

  3                   0,2

  3,7                 0,6

  4                   0,6

  4,2                 0,9

  5                   0,9

  5,5                 1

  6                   1
  -----------------------------------------------------------------------

В правом столбце -- сумма частот вариантов, меньших х.

Как это отобразить:

Строим *кумуляту.*

Строим отдельно для абсолютных частот и относительных.

Накопленная абсолютная частота для значения х, равного варианту

  -----------------------------------------------------------------------
  Значение х                          Накопленная абсолютная частота для
                                      значения х
  ----------------------------------- -----------------------------------
  2                                   0

  3                                   2

  4                                   6

  5                                   9
  -----------------------------------------------------------------------

Кумулята для относительных частот:

  -----------------------------------------------------------------------
  Значение х                          Накопленная частота для значения х
  ----------------------------------- -----------------------------------
  2                                   0

  3                                   0,2

  4                                   0,6

  5                                   0,9
  -----------------------------------------------------------------------

# Интервальный вариационный ряд и его графическое изображение

Пример про рост студентов:

Рассмотрим интервальный вариационный ряд.

Ранжированные варианты:

  -------------------------------------------------------------------------------
  160     163     168     170     174     175     177     184     189     195
  ------- ------- ------- ------- ------- ------- ------- ------- ------- -------

  -------------------------------------------------------------------------------

  ------------------------------------------------------------------------
  Вариант                 Абсолютная частота      Относительная частота
  ----------------------- ----------------------- ------------------------
  160                     1                       0,1

  163                     1                       0,1

  168                     1                       0,1

  170                     1                       0,1

  174                     1                       0,1

  175                     1                       0,1

  177                     1                       0,1

  184                     1                       0,1

  189                     1                       0,1

  195                     1                       0,1
  ------------------------------------------------------------------------

Группируем варианты:

Разбиваем по интервалу

Число интервалов:

$$k = 1 + \left| 0,5 + {log_{2}}n \right|$$

Длина интервала:

$$L = \backslash frac\{ x\_\{ max\} - x\_\{ min\}\}\{ k\}$$

Для нашего случая:

K = 1 + $0,5\  + \ \log_{2}10$ = 4 -- число интервалов

L = (195 - 160) / 4 = 8,75 см.

Интервалы

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image48.png)
Составим абсолютные частоты для
интервалов:

  -----------------------------------------------------------------------
  Интервал, см             Абсолютная частота для интервала
  ------------------------ ----------------------------------------------
  \[160; 168,75\]          3

  \[168,75; 177,5\]        4

  \[177,5; 186,25\]        1

  \[186,25; 195\]          2
  -----------------------------------------------------------------------

Относительные частоты для интервалов:

  -----------------------------------------------------------------------
  Интервал, см                        Частота для интервала
  ----------------------------------- -----------------------------------
  \[160; 168,75\]                     0,3

  \[168,75; 177,5\]                   0,4

  \[177,5; 186,25\]                   0,1

  \[186,25; 195\]                     0,2
  -----------------------------------------------------------------------

Получили интервальный вариационный ряд для абсолютных частот и
относительных частот.

Дальше строим ненормированную гистограмму:

Ненормированная гистограмма -- сумма площадей всех столбиков не равна
единице (в общем случае).

Считаем накопленную абсолютную частоту:

  -----------------------------------------------------------------------
  Интервал, см                        Накопленная абсолютная частота для
                                      интервала
  ----------------------------------- -----------------------------------
  \[160; 168,75\]                     3

  \[168,75; 177,5\]                   7

  \[177,5; 186,25\]                   8

  \[186,25; 195\]                     10
  -----------------------------------------------------------------------

После строим кумуляту, и накладываем ее на гистограмму.

Такие же действия производим и для относительных частот.

# Средние величины вариационного ряда

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image49.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image50.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image51.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image52.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image53.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image54.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image55.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image56.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image57.png)


# Показатели вариации

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image58.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image59.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image60.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image61.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image62.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image63.png)


# Начальные и центральные моменты вариационного ряда

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image64.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image65.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image66.png)

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image67.png)


# Оценка числовых характеристик случайной величины

Среднее арифметическое элементов выборки -- это случайная величина.

Каждое вычисленное ее значение -- реализация этой случайной величины.

Значение оценки мат.ожидания

$$\widehat{m_{x}} = \frac{1}{n}*\sum_{i\  = \ 1}^{n}x_{i}$$

Значение оценки дисперсии:

$$\widehat{D_{x}} = \frac{n}{n - 1}\ *\ (\frac{1}{n}*\sum_{i = \ \ 1}^{n}{x_{i}^{2} - {\widehat{m}}_{x}^{2}})$$

Значение оценки среднего квадратичного отклонения

$${\widehat{\sigma}}_{x} = C(n)\ *\ \sqrt{{\widehat{D}}_{X}}$$

Значение оценки мат.ожидания случайной величины Х

$$\widehat{m_{Х}} = \frac{1}{n}*\sum_{i\  = \ 1}^{n}x_{i}$$

Значение оценки дисперсии для случайной величины Х

$$\widehat{D_{Х}} = \frac{n}{n - 1}\ *\ (\frac{1}{n}*\sum_{i = \ \ 1}^{n}{x_{i}^{2} - {\widehat{m}}_{Х}^{2}})$$

Значение оценки среднего квадратического отклонения случайной величины Х

$${\widehat{\sigma}}_{X} = C(n)\ *\ \sqrt{{\widehat{D}}_{X}}$$

Значение оценки мат.ожидания случайной величины Y

$$\widehat{m_{Y}} = \frac{1}{n}*\sum_{i\  = \ 1}^{n}y_{i}$$

Значение оценки дисперсии для случайной величины Y

$$\widehat{D_{Y}} = \frac{n}{n - 1}\ *\ (\frac{1}{n}*\sum_{i = \ \ 1}^{n}{y_{i}^{2} - {\widehat{m}}_{Y}^{2}})$$

Значение оценки среднего квадратического отклонения случайной величины Y

$${\widehat{\sigma}}_{Y} = C(n)\ *\ \sqrt{{\widehat{D}}_{Y}}$$

Значение оценки ковариации

$${\widehat{K}}_{XY} = \frac{n}{n\  - \ 1}*(\frac{1}{n}*\sum_{i = 1}^{n}{x_{i}*y_{i} - {\widehat{m}}_{X}*{\widehat{m}}_{Y}})$$

Значение оценки коэффициента корреляции

$${\widehat{r}}_{XY} = \frac{{\widehat{K}}_{XY}}{{\widehat{\sigma}}_{X}*{\widehat{\sigma}}_{Y}}$$

# Оценка параметров закона распределения случайной величины

Биномиальное распределение

$$\widehat{k} = \frac{{\widehat{m}}_{X}^{2}}{{\widehat{m}}_{X} - {\widehat{D}}_{X}}$$

$$\widehat{p} = 1 - \frac{{\widehat{D}}_{X}}{{\widehat{m}}_{X}}$$

При известном к:

$$\widehat{p} = \frac{{\widehat{m}}_{X}}{k}$$

Распределение Пуассона

Для дискретной случайной величины Х, имеющей распределение Пуассона с
параметром а, значение оценки этого параметра вычисляется так:

Равномерный закон распределения:

Для непрерывной случайной величины Х, имеющей равномерный закон
распределения с параметрами a и b, значения оценок этих параметров
вычисляются так:

Экспоненциальный закон распределения:

Для непрерывной случайной величины Х, имеющей экспоненциальный закон
распределения с параметром a, значение оценки этого параметра
вычисляется так:

$$\widehat{a} = \frac{1}{{\widehat{m}}_{X}}$$

Нормальный закон распределения:

$$\widehat{a} = {\widehat{m}}_{X}$$

$$\widehat{\sigma} = {\widehat{\sigma}}_{X}$$

Пусть x_1, x_2, x_3, ..., x_n -- это выборка объема n \> 1 реализаций
любой случайной величины Х, причем элементы этой выборки упорядочены по
неубыванию:

X_1 \<= x_2 \<= x_3 \< ... \< x_n.

Обозначим N(x) -- число элементов выборки, строго меньших х.

$$\widehat{F}(x)\  = \ \frac{N(x)}{n}$$

Доверительные интервалы

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image68.png)


# Оценка плотности вероятности НСВ

* *Функция *f*(*x*), называемая **плотностью распределения **непрерывной
случайной величины, определяется по формуле:

*f* (*x*) = *F′*(*x*),

то есть является производной функции распределения.

Свойства плотности распределения.

1.  *f*(*x*) ≥ 0, так как функция распределения является неубывающей.

2.  ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image69.png)
    , что следует из определения плотности
    распределения.

3.  Вероятность попадания случайной величины в интервал (*а, b*)
    определяется
    формулой ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image70.png)
    * *Действительно, ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image71.png)
    

4.  ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image72.png)
    (условие нормировки). Его справедливость следует из
    того,
    что ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image73.png)
    а![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image74.png)
    

5.  ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image75.png)
    так
    как ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image76.png)
    при![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image77.png)
    

Таким образом, график плотности распределения представляет собой кривую,
располо-женную выше оси О*х*, причем эта ось является ее горизонтальной
асимптотой
при ![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image78.png)
(последнее справедливо только для случайных величин,
множеством возможных значений которых является все множество
действительных чисел). Площадь криволинейной трапеции, ограниченной
графиком этой функции, равна единице.

*Замечание. *Если все возможные значения непрерывной случайной величины
сосредоточе-ны на интервале \[*a, b*\], то все интегралы вычисляются в
этих пределах, а вне интервала \[*a, b*\] *f*(*x*) ≡ 0.

# Понятие доверительного интервала

Доверительный интервал для параметра -- интервал, который с заданной
вероятностью «накрывает» неизвестное значение этого параметра;

Эта вероятность называется доверительной вероятностью;

Границы такого интервала называются доверительными границами.

Доверительные границы -- случайные величины.

Для конкретной выборки вычисляются реализации этих случайных величин,
называемые значениями доверительных границ.

Для конкретной выборки значения a1 и a2 доверительных границ образуют
значение доверительного интервала (a1, a2).

Значение доверительного интервала может «накрыть» неизвестное значение
параметра.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image79.png)


Значение доверительного интервала может не «накрыть» неизвестное
значение параметра.

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image80.png)
 Пытаемся «накрыть» значением
доверительного интервала неизвестное значение параметра

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image81.png)


Доверительная вероятность

$$\gamma\  = \ P(A_{1} < a < A_{2})$$

$\gamma$ -- доверительная вероятность

$A_{1}$ -- левая доверительная граница (случайная величина)

$A_{2}$ -- правая доверительная граница (случайная величина)

а -- неизвестное значение параметра.

# Доверительный интервал для математического ожидания. Пример

Приближенные формулы для значений доверительных границ

a1
$\approx {\widehat{m}}_{x} - T(\gamma)\frac{{\widehat{\sigma}}_{x}}{\sqrt{n}}$
-- значение левой границы

a1
$\approx {\widehat{m}}_{x} + T(\gamma)\frac{{\widehat{\sigma}}_{x}}{\sqrt{n}}$
-- значение правой границы

![](~/Repositories/university/probability-theory-and-mathematical-statistics/media/image82.png)


# Доверительный интервал для вероятности события. Пример

Значения доверительных границ $a_{1}\ и\ a_{2}$ значения доверительного
интервала ($a_{1},\ a_{2}$) для вероятности события А при заданной
доверительной вероятности $\gamma$ вычисляются по приближенным формулам.

$$a_{1} \approx \frac{n}{n + T^{2}(\gamma)}\left( \widehat{p} + \frac{T^{2}(\gamma)}{2*n} - T(\gamma)\sqrt{\frac{\widehat{p}\left( 1 - \widehat{p} \right)}{n} + \left( \frac{T(\gamma)}{2*n} \right)^{2}} \right)$$

$$a_{2} \approx \frac{n}{n + T^{2}(\gamma)}(\widehat{p} + \frac{T^{2}(\gamma)}{2*n} + T(\gamma)\sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n} + {(\frac{T(\gamma)}{2*n})}^{2}})$$

Здесь $\widehat{p} = \frac{k}{n}\ $ - значение оценки вероятности
события А;

$T(\gamma)$ *--* та же табулированная функция, что и для значения
доверительных границ для математического ожидания.

При n \> 200 для значений доверительных границ $a_{1}\ и\ a_{2}$
значения доверительного интервала ($a_{1},\ a_{2}$) для вероятности
события А при заданной доверительной вероятности события $\gamma$ можно
использовать приближенные формулы.

$$a_{1} \approx \widehat{p}\  - \ T(\gamma)\sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}}$$

$$a_{2} \approx \widehat{p} + T(\gamma)\sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}}$$
